import streamlit as st
import pandas as pd
import numpy as np
import plotly.express as px
import matplotlib.pyplot as plt
import seaborn as sns
import networkx as nx
import os
from datetime import timedelta

# Custom modules
from modules.embedding_utils import compute_text_similarity
from modules.clustering_utils import cluster_texts, build_user_interaction_graph

st.set_page_config(page_title="CIB Dashboard", layout="wide")
st.title("üïµÔ∏è Coordinated Inauthentic Behavior (CIB) Network Monitoring Dashboard")

# === Sidebar: Upload File ===
st.sidebar.header("üìÅ Upload Dataset")
uploaded_file = st.sidebar.file_uploader("Upload a CSV/TSV file", type=["csv", "tsv"])

# === Column standardization map ===
col_map = {
    'Influencer': 'Source',
    'authorMeta/name': 'Source',
    'media_name': 'Source',
    'channeltitle': 'Source',

    'Hit Sentence': 'text',
    'message': 'text',
    'title': 'text',

    'Date': 'Timestamp',
    'createTimeISO': 'Timestamp'
}

required_columns = ["Source", "Timestamp", "text", "URL", "Platform"]

# === Load dataset ===
if uploaded_file is not None:
    try:
        df = pd.read_csv(uploaded_file, encoding='utf-16', sep='\t', low_memory=False)
        st.sidebar.success("‚úÖ File uploaded.")
    except Exception as e:
        st.sidebar.error(f"‚ùå Failed to read uploaded file: {e}")
        st.stop()
else:
    default_url = "https://raw.githubusercontent.com/hanna-tes/CIB-network-monitoring/refs/heads/main/Togo_OR_Lome%CC%81_OR_togolais_OR_togolaise_AND_manifest%20-%20Jul%207%2C%202025%20-%205%2012%2053%20PM.csv"
    try:
        df = pd.read_csv(default_url, encoding='utf-16', sep='\t', low_memory=False)
        st.sidebar.warning("‚ö†Ô∏è Using default dataset from GitHub.")
    except Exception as e:
        st.error(f"‚ùå Failed to load default dataset: {e}")
        st.stop()

# === Standardize columns BEFORE validation ===
df.columns = [col_map.get(col.strip(), col.strip()) for col in df.columns]

# === Validate required columns ===
missing = [col for col in required_columns if col not in df.columns]
if missing:
    st.sidebar.error(f"‚ùå Missing required columns: {missing}")
    st.stop()

# === Final cleanup ===
df = df[required_columns].copy()
df["Timestamp"] = pd.to_datetime(df["Timestamp"], errors="coerce")
df.dropna(subset=["Timestamp", "text"], inplace=True)

# --- Sidebar: Export ---
st.sidebar.markdown("### üì§ Export Results")
def convert_df(data):
    return data.to_csv(index=False).encode('utf-8')

csv_data = convert_df(df)
st.sidebar.download_button("Download Full Data", csv_data, "processed_data.csv", "text/csv")

# --- Tabs ---
tab1, tab2, tab3 = st.tabs(["üìä Overview", "üîç Analysis", "üåê Network & Risk"])

# ==================== TAB 1 ====================
with tab1:
    st.subheader("üìå Summary Statistics")

    st.markdown("**Top Sources (by post count):**")
    top_sources = df['Source'].value_counts().head(10)
    st.bar_chart(top_sources)

    st.markdown("**Top Hashtags (by frequency):**")
    df['hashtags'] = df['text'].str.findall(r"#\w+")
    all_hashtags = pd.Series([tag for tags in df['hashtags'] for tag in tags])
    st.bar_chart(all_hashtags.value_counts().head(10))

    st.markdown("**Posting Spikes Over Time**")
    time_series = df.groupby(pd.to_datetime(df['Timestamp']).dt.date).size()
    st.line_chart(time_series)

# ==================== TAB 2 ====================
with tab2:
    st.subheader("üß† Similarity & Coordination Detection")
    
    # Text Similarity
    st.markdown("This table displays groups of posts that are textually similar, possibly indicating coordinated messaging.")
    try:
        text_sim_df = compute_text_similarity(df)
        if not text_sim_df.empty:
            st.dataframe(text_sim_df[['text1', 'source1', 'time1', 'text2', 'source2', 'time2', 'similarity']])
        else:
            st.info("No significant text similarities found.")
    except Exception as e:
        st.warning(f"‚ö†Ô∏è Similarity computation failed: {e}")

    # Visual Similarity (CLIP)
    #st.markdown("This table shows image pairs with visual or visual-textual similarities using CLIP.")
    #if 'image_path' in df.columns:
     #   clip_df = compute_visual_clip_similarity(df)
      #  if not clip_df.empty:
      #      st.dataframe(clip_df[['image1', 'image2', 'clip_score']])
     #   else:
       #     st.info("No visually similar content detected.")

# ==================== TAB 3 ====================
with tab3:
    st.subheader("üö® High-Risk Accounts & Networks")

    # Clustering for High-Risk Account Grouping
    st.markdown("Accounts have been grouped by coordination patterns (hashtags, URLs, posting behavior). Each cluster may indicate potential coordinated activity.")
    try:
        clustered_df = cluster_texts(df)
        cluster_counts = clustered_df['cluster'].value_counts()
        st.dataframe(clustered_df[['Source', 'text', 'Timestamp', 'cluster']])
    except Exception as e:
        st.warning(f"‚ö†Ô∏è Clustering failed: {e}")

    # Network Graph
    st.markdown("This network graph shows user interactions, clustered by behavioral similarities. Color represents different coordination clusters.")
    try:
        G, pos, cluster_map = build_user_interaction_graph(df)
        fig, ax = plt.subplots(figsize=(10, 7))
        nx.draw(G, pos, with_labels=True, node_color=[cluster_map.get(n, 0) for n in G.nodes], cmap=plt.cm.Set3, node_size=500, edge_color="gray", ax=ax)
        st.pyplot(fig)
    except Exception as e:
        st.warning(f"‚ö†Ô∏è Network graph failed: {e}")
